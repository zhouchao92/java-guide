# 有状态流式处理引擎的基石【重点】

[【【Apache Flink 入门教程】2. Apache Flink 概念介绍：有状态流式处理引擎的基石】](https://www.bilibili.com/video/BV1qb411H7mY)

[Flink 基本概念.pdf](./ppt/1.2%20Flink基本概念.pdf)

[官方文档：有状态流处理](https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/concepts/stateful-stream-processing/)

- 状态容错（State Fault Tolerance）：精确一次保证，分布式快照。
	- checkpoint 检查点，分布式（Global Consistent Snapshot）状态容错，共享的 DFS。
	-	checkpoint barrier n 不中断运算，chandy lamport 衍生算法（不依赖锁生成分布式snapshot）。
- 状态维护（State Management）：本地状态后端，技术选型（JVM Heap 状态后端/Rocks DB 状态后端）
	- JVM Heap 状态后端：状态变化过程中，仅有 Java Object 层次操作（资源消耗大），在生成 Distributed Snapshots 时需要序列化、IO（资源消耗大）。
	- Rocks DB 状态后端：状态变化过程中，需要序列化、IO（资源消耗大），在生成 Distributed Snapshots 时持久化到 DFS。
- Event-Time 处理（Event-Time Processing）：WaterMarks 水位线，一个带有时间戳 t 的 watermark 会让运算元判定不会再收到任何时间戳 < t 的事件。
	- Event-Time 表示事件发生的时间
	- Processing-Time 则表示处理消息的时间（墙上时间）
	- Ingestion-Time 表示进入到系统的时间
- 状态保存与迁移（Savepoints and Job Migration）
	- Savepoint 保存点：可以想象为一个手动产生的 checkpoint，保存点记录着流式应用中所有运算元的状态。


savepoint 和 checkpoint 的区别： 
- checkpoint 是增量做的，每次的时间较短，数据量较小，只要在程序里面启用后会自动触发，用户无须感知；savepoint 是全量做的，每次的时间较长，数据量较大，需要用户主动去触发。 
- checkpoint 是作业 failover 的时候自动使用，不需要用户指定。savepoint 一般用于程序的版本更新，bug 修复，A/B Test 等场景，需要用户指定。


# Flink 安装部署、环境配置及运行应用程序【看文档】

[【【Apache Flink 入门教程】3. Flink 安装部署、环境配置及运行应用程序】](https://www.bilibili.com/video/BV1wb41177T7)

[Flink 安装部署、环境配置及运行应用程序.pdf](./ppt/1.3%20Flink%20安装部署、环境配置及运行应用程序.pdf)

[flink-1.13.6 源码](https://archive.apache.org/dist/flink/flink-1.13.6/)

[官方编译指南](https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/flinkdev/building/)


Flink运行时包括两类进程： 
- JobManager（又称为 JobMaster）：协调 Task 的分布式执行，包括调度 Task、协调创建 checkpoint 以及当 job failover 时协调各个 Task 从 checkpoint 恢复等。 
- TaskManager（又称为 Worker）：执行 dataflow 中的 Tasks，包括内存 buffer 的分配、
Data Stream的传递等。 


# DataStream API 编程

[【【Apache Flink 入门教程】4.DataStream API 编程】](https://www.bilibili.com/video/BV1yb411s7h4)

[DataStream API 编程.pdf](./ppt/1.4%20DataStream%20API编程.pdf)

![DataStream 基本转换](/pic/flink/Flink%20DataStream%20基本转换.png)

![DataStream API 原理](/pic/flink/Flink%20DataStream%20API%20原理.png)

![DataStream API 总结](/pic/flink/Flink%20DataStream%20API%20总结.png)

案例中 `fold` 函数已废弃，可以用 `reduce` 函数实现同样的效果

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setParallelism(2);

// 添加模拟数据源
DataStreamSource<Tuple2<String, Integer>> dataStreamSource = env.addSource(new RichSourceFunction<Tuple2<String, Integer>>() {
		private volatile boolean running = true;

		@Override
		public void run(SourceContext<Tuple2<String, Integer>> sourceContext) throws Exception {
				Random random = new Random(System.currentTimeMillis());

				while (running) {
						Thread.sleep((getRuntimeContext().getIndexOfThisSubtask() + 1) * 1000L + 500);
						String key = "类别" + (char) ('A' + random.nextInt(3));
						int value = random.nextInt(10) + 1;

						System.out.printf("Emit:\t(%s, %d)%n", key, value);

						sourceContext.collect(new Tuple2<>(key, value));
				}
		}

		@Override
		public void cancel() {
				running = false;
		}
});

/*KeyedStream<Tuple2<String, Integer>, Tuple> tuple2TupleKeyedStream = dataStreamSource.keyBy(0);
tuple2TupleKeyedStream.sum(1);*/

dataStreamSource.keyBy(new KeySelector<Tuple2<String, Integer>, Object>() {
		@Override
		public Object getKey(Tuple2<String, Integer> stringIntegerTuple2) throws Exception {
				// 分组条件1
				// return stringIntegerTuple2.f0;
				// 不分组
				return "";
		}
}).reduce(new ReduceFunction<Tuple2<String, Integer>>() {
		@Override
		public Tuple2<String, Integer> reduce(Tuple2<String, Integer> stringIntegerTuple2, Tuple2<String, Integer> t1) throws Exception {
				return Tuple2.of(t1.f0, t1.f1 + stringIntegerTuple2.f1);
		}
}).addSink(new SinkFunction<Tuple2<String, Integer>>() {
		@Override
		public void invoke(Tuple2<String, Integer> value, Context context) throws Exception {
				System.out.printf("Merge:\t%d%n", value.f1);
		}
});

dataStreamSource.addSink(new SinkFunction<Tuple2<String, Integer>>() {
		@Override
		public void invoke(Tuple2<String, Integer> value, Context context) throws Exception {
				System.out.printf("Get:\t(%s, %d)%n", value.f0, value.f1);
		}
});

env.execute();

```


# 客户端操作【看文档】

[【【Apache Flink 入门教程】5. 客户端操作】](https://www.bilibili.com/video/BV1Yb411x7xD)

[客户端操作.pdf](./ppt/1.5%20客户端操作.pdf)

[flink 执行计划可视化](http://flink.apache.org/visualizer/)


# Window & Time

[【【Apache Flink 入门教程】6. Flink Window、Time】](https://www.bilibili.com/video/BV1db411L7fT)

[Window & Time.pdf](./ppt/1.6%20Window%20&%20Time.pdf)

[官方文档：Watermark生成](https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/dev/datastream/event-time/generating_watermarks/)

- Tumbling Window （窗口间的元素无重复）
- Sliding Window（窗口间的元素可能重复）
- Session Window 以及 Global Window 


# 状态管理与容错机制

[【【Apache Flink 入门教程】7. 状态管理与容错机制】](https://www.bilibili.com/video/BV1fb41157Li)

[状态管理与容错机制.pdf](./ppt/1.7%20状态管理与容错机制.pdf)

[官方文档：状态管理](https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/dev/datastream/fault-tolerance/state/)

[官方文档：容错处理](https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/learn-flink/fault_tolerance/)


# Flink Table API 编程【看文档】

[【【Apache Flink 入门教程】8. Flink Table API 编程】](https://www.bilibili.com/video/BV19441187b6)

[Flink Table API 编程.pdf](./ppt/1.8%20Flink%20Table%20API%20编程.pdf)

[官方文档：Table API](https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/dev/table/tableapi/)

![Flink Table Column API 总结](/pic/flink/Flink%20Table%20Column%20API%20总结.png)

![Flink Table Row API 总结](/pic/flink/Flink%20Table%20Row%20API%20总结.png)

[demo 源码](https://github.com/hequn8128/TableApiDemo)


# Flink SQL 编程【实操讲解】

[【【Apache Flink 入门教程】9. Flink SQL 编程】](https://www.bilibili.com/video/BV1m441147TZ)

[Flink SQL 编程.pdf](./ppt/1.9%20Flink%20SQL%20编程.pdf)

[官方文档：SQL](https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/dev/table/sql/overview/)

![Flink Window Aggregation 对比 Group Aggregation](/pic/flink/Flink%20Window%20Aggregation%20对比%20Group%20Aggregation.png)

[源码](https://github.com/ververica/sql-training/)


# Flink 知识点补充

## 反压（通义千问）
Flink 中的反压（Backpressure）是指当下游操作符处理数据的速度慢于上游操作符产生数据的速度时发生的现象。这种情况下，上游操作符会减缓其数据生成速度以避免数据丢失或内存溢出。Flink 通过反压机制来确保流处理作业的端到端的背压感知性，从而实现可靠的处理。

### 如何检测反压
Flink 提供了多种方式来检测反压：

- 任务管理器的日志 - 任务管理器会在日志中记录反压情况。
- Flink Web UI - 你可以在 Flink 的 Web UI 中查看每个算子的输入和输出缓冲区的大小，以及是否发生了反压。
- Flink Metrics - 如果启用了 Flink 的 Metrics，则可以通过 Metrics 查看反压相关的指标。

### 如何解决反压

- 增加并行度 - 增加出现反压的操作符的并行度可以帮助缓解反压。这通常意味着更多的资源将被分配给该操作符。
- 优化算子 - 优化导致瓶颈的算子，比如减少计算复杂性或使用更高效的算法。
- 调整序列化/反序列化逻辑 - 有时候序列化/反序列化过程可能会成为瓶颈。考虑使用更高效的数据序列化框架，如 Kryo 或 Avro。
- 增加资源 - 为集群增加更多的资源，比如更多的任务管理器或更大的内存。
- 数据分区 - 调整数据分区策略，确保数据在操作符之间均匀分布。

### 示例：检查反压
在 Flink 的 Web UI 中，你可以通过以下步骤来检查反压情况：

1. 打开 Flink 的 JobManager Web UI。
2. 导航到“Jobs”页面。
3. 选择运行中的作业。
4. 在作业详情页面中，选择 “Task Managers” 标签页。
5. 查看每个 Task Manager 的输入和输出缓冲区的状态。

### 示例：解决反压
假设你有一个作业，其中一个 Map 操作符出现了反压，你可以尝试以下解决方案：

1. 增加并行度 - 你可以通过修改作业配置来增加 Map 操作符的并行度。
2. 优化 Map 函数 - 重新编写 Map 函数以提高效率，例如通过减少不必要的计算或使用更高效的集合。
3. 使用缓存 - 如果 Map 函数涉及外部数据源的访问，考虑使用缓存来减少延迟。



